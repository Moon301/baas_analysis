{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f904e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "EV Performance\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"EV Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66c1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public 스키마 테이블 목록: ['bw_segment_states', 'battery_performance_ranking', 'bw_segments', 'bw_data', 'bw_dashboard', 'car_type', 'bw_vehicle_status', 'battery_performance_scores_per_segment', 'mv_dashboard_stats', 'mv_dashboard_car_type_stats', 'mv_bw_monthly', 'ev_battery_capacity', 'bw_charging_type']\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    port=5432,\n",
    "    dbname='postgres',\n",
    "    user='postgres',\n",
    "    password='keti1234!'\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "# cur.execute(\n",
    "#     \"\"\"\n",
    "#     SELECT table_name \n",
    "#     FROM information_schema.tables \n",
    "#     WHERE table_schema = 'public'\n",
    "#     ORDER BY table_name\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "cur.execute(\n",
    "    \"\"\"\n",
    "SELECT c.relname AS object_name,\n",
    "       d.description\n",
    "FROM pg_class c\n",
    "LEFT JOIN pg_description d ON d.objoid = c.oid\n",
    "WHERE c.relkind IN ('r','m','v')  -- r=table, m=matview, v=view\n",
    "  AND c.relnamespace = 'public'::regnamespace;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "tables = cur.fetchall()\n",
    "\n",
    "table_list = [t[0] for t in tables]\n",
    "print(\"Public 스키마 테이블 목록:\", table_list)\n",
    "    \n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8504f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b08dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgeneral_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**bw_data 상위 10개 행 조회하기**\n",
      "\n",
      "아래 예시는 **SQL**과 **Python (pandas)** 두 가지 방법을 함께 안내해 드립니다.  \n",
      "필요한 환경에 맞게 한 가지 방법을 선택해서 사용하시면 됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ SQL 으로 조회 (MySQL / PostgreSQL / SQLite 등)\n",
      "\n",
      "```sql\n",
      "-- 가장 상위 10개의 행을 가져옵니다\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "LIMIT 10;          -- MySQL / PostgreSQL / SQLite\n",
      "-- 또는\n",
      "SELECT TOP 10 *\n",
      "FROM bw_data;      -- SQL Server\n",
      "```\n",
      "\n",
      "- `LIMIT 10` : 첫 번째 10개 행을 가져옵니다.  \n",
      "- `TOP 10` : SQL Server 전용 구문입니다.\n",
      "\n",
      "필요하다면 정렬 기준을 지정해서 가장 최근 기록이 나올 수 있도록 할 수도 있습니다.\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "ORDER BY created_at DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Python (pandas) 으로 조회\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# 예시: CSV 파일이 있는 경우\n",
      "# df = pd.read_csv('bw_data.csv')\n",
      "\n",
      "# 혹은 데이터베이스에서 바로 읽어올 때\n",
      "# conn = ...  # DB 연결\n",
      "# df = pd.read_sql('SELECT * FROM bw_data', conn)\n",
      "\n",
      "# 상위 10개 행 확인\n",
      "top10 = df.head(10)\n",
      "print(top10)\n",
      "```\n",
      "\n",
      "- `df.head(10)` : DataFrame의 첫 10개 행을 반환합니다.  \n",
      "- 데이터베이스에서 직접 읽어올 때는 `pd.read_sql()`을 사용하면 편리합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Jupyter Notebook 등에서 바로 시각화\n",
      "\n",
      "```python\n",
      "top10.style.set_caption('bw_data 상위 10개 행')\n",
      "```\n",
      "\n",
      "위 코드를 실행하면 표가 깔끔하게 표시됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 참고사항\n",
      "\n",
      "- **데이터베이스 연결**: `pandas.read_sql()` 를 사용할 때는 `sqlalchemy` 또는 `psycopg2`, `pymysql` 등 연결 드라이버가 필요합니다.  \n",
      "- **데이터가 클 때**: `LIMIT 10` 대신 `FETCH FIRST 10 ROWS ONLY` 같은 ANSI SQL 구문을 사용해도 무방합니다.  \n",
      "- **정렬 없이 조회**: 테이블이 인덱스나 파티션에 따라 순서가 보장되지 않을 수 있으니, 꼭 필요한 경우는 `ORDER BY` 를 명시해 주세요.\n",
      "\n",
      "필요하신 부분이 더 있으면 언제든 말씀해 주세요! 🚀\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import invoke_graph, stream_graph, random_uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "select_model = \"gpt-oss:20b\" #  FRONTEND 에서 넘어온 모델 정보\n",
    "\n",
    "class EvState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    db_info: Annotated[list, \"DB Info\"]  # DB 정보\n",
    "    user_question: Annotated[str, \"Question\"]  # 사용자 질문\n",
    "    db_query:  Annotated[str, \"DB Query\"]  # DB 쿼리 생성\n",
    "    db_result: Annotated[str, \"DB Answer\"]  # DB 쿼리 답변\n",
    "    \n",
    "    \n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "\n",
    "    # 데이터 소스 선택을 위한 리터럴 타입 필드\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question, 전기차, 배터리등과 같은 질문이면 'yes'를 반환하고 그렇지 않으면 'no'를 반환하세요.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# router\n",
    "def router_question_node(state: EvState) -> EvState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "    \n",
    "    # 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "    system = \"\"\"You are an expert at routing a user question. 전기차, 배터리등과 같은 질문이면 'yes'를 반환하고 그렇지 않으면 'no'를 반환하세요.\"\"\"\n",
    "\n",
    "    # Routing 을 위한 프롬프트 템플릿 생성\n",
    "    route_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 프롬프트 템플릿과 구조화된 LLM 라우터를 결합하여 질문 라우터 생성\n",
    "    question_router = route_prompt | structured_llm_router\n",
    "    response = question_router.invoke(state[\"user_question\"])\n",
    "    \n",
    "    if response.binary_score == \"yes\":\n",
    "        return \"db_search\"\n",
    "    else:\n",
    "        return \"general_answer\"\n",
    "# 노드\n",
    "\n",
    "# 일반 답변 노드\n",
    "def general_answer(state: EvState) -> EvState:\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"당신은 친절한 상담사 KETI 입니다. 사용자의 질문에 대해 친절하게 답변해주세요.\"),\n",
    "            (\"user\", \"다음 질문에 대한 답변을 생성해주세요: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | ChatOllama(model=select_model)\n",
    "    \n",
    "    response = chain.invoke({\"question\": state[\"user_question\"]})\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# DB 테이블 조회 노드\n",
    "\n",
    "def db_search(state: EvState) -> EvState:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT c.relname AS object_name,\n",
    "        d.description\n",
    "    FROM pg_class c\n",
    "    LEFT JOIN pg_description d ON d.objoid = c.oid\n",
    "    WHERE c.relkind IN ('r','m','v')  -- r=table, m=matview, v=view\n",
    "    AND c.relnamespace = 'public'::regnamespace;\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    tables = cur.fetchall()\n",
    "\n",
    "    table_list = [t[0] for t in tables]\n",
    "    print(\"Public 스키마 테이블 목록:\", table_list)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return {\"db_info\": table_list}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DB 쿼리 생성 노드\n",
    "def generate_query(state: EvState) -> EvState:\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a helpful assistant that generates 포스트그래 SQL queries. 다른 설명은 하지말고 쿼리문만 생성해\"),\n",
    "            (\"user\", \"Generate a SQL query to answer the following question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | ChatOllama(model=select_model)\n",
    "    response = chain.invoke({\"question\": state[\"user_question\"]})\n",
    "    return {\"db_query\": response.content}\n",
    "\n",
    "\n",
    "# DB 조회 노드\n",
    "def db_query(state: EvState) -> EvState:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        port=5432,\n",
    "        dbname='postgres',\n",
    "        user='postgres',\n",
    "        password='keti1234!'\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    query = state[\"db_query\"].replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchall()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return {\"db_result\": result}\n",
    "\n",
    "# 분석 답변 노드\n",
    "def analyze_answer(state: EvState) -> EvState:\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"DB에서 조회된 다음 내용을 보고 사용자가 질문을 분석한 내용을 답변하세요.  db_result:\\n{db_result}\"),\n",
    "            (\"user\", \"Generate a SQL query to answer the following question: {question}\"),\n",
    "        ]\n",
    "        )\n",
    "    chain = prompt | ChatOllama(model=select_model)\n",
    "    response = chain.invoke({\"question\": state[\"user_question\"],\"db_result\": state[\"db_result\"] })\n",
    "\n",
    "    \n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "workflow = StateGraph(EvState)\n",
    "\n",
    "# 노드를 추가합니다.\n",
    "workflow.add_node(\"router_question_node\", router_question_node)\n",
    "workflow.add_node(\"general_answer\", general_answer)\n",
    "workflow.add_node(\"db_gen_query\", db_query)\n",
    "workflow.add_node(\"generate_query\", generate_query)\n",
    "workflow.add_node(\"analyze_answer\", analyze_answer)\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    router_question_node,\n",
    "    {\n",
    "        \"db_search\": \"generate_query\",\n",
    "        \"general_answer\": \"general_answer\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"generate_query\", \"db_gen_query\")\n",
    "workflow.add_edge(\"db_gen_query\", \"analyze_answer\")\n",
    "workflow.add_edge(\"analyze_answer\", END)\n",
    "workflow.add_edge(\"general_answer\", END)\n",
    "\n",
    "\n",
    "# 기록을 위한 메모리 저장소를 설정합니다.\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프를 컴파일합니다.\n",
    "app= workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "\n",
    "# 질문 입력\n",
    "inputs = EvState(user_question=\"bw_data 상위 열개 조회\")\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e9f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgeneral_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "저도 만나서 반가워요! 언제든 궁금한 점이나 도움이 필요하시면 편하게 말씀해 주세요. 😊\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "response = invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e0e3326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 만나서 반갑습니다 😊  \\n저는 KETI 상담사입니다. 무엇을 도와드릴까요? 궁금한 점이나 필요하신 정보가 있으면 언제든 말씀해 주세요!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = app.invoke(inputs, config)\n",
    "\n",
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f4f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgeneral_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요! 만나서 반가워요 😊  \n",
      "무엇을 도와드릴까요? 궁금한 점이나 필요한 내용이 있으면 언제든 말씀해 주세요!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 질문 입력\n",
    "inputs = EvState(user_question=\"만나서 반가워\")\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4098e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_query\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mdb_query\u001b[0m:\n",
      "SELECT * FROM bw_data LIMIT 10;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mdb_gen_query\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 23, 465000), 54784.0, 79.5, 100.0, 363.4, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.025111111111107, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 26, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.024888888888885, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 29, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.025999999999995, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 32, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.026222222222217, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 35, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.026666666666663, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 38, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.026888888888885, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 41, 466000), 54784.0, 79.5, 100.0, 363.5, 17.7, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027111111111108, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 45, 465000), 54784.0, 79.5, 100.0, 363.5, 17.7, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027111111111107, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 48, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027555555555552, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 51, 465000), 54784.0, 79.5, 100.0, 363.5, 17.7, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027333333333329, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36manalyze_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mmessages\u001b[0m:\n",
      "아래와 같이 **`bw_data`** 테이블의 상위 10개의 레코드를 조회할 수 있습니다.  \n",
      "\n",
      "```sql\n",
      "-- 가장 최근 10개의 레코드를 가져오려면\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "ORDER BY <타임스탬프컬럼> DESC   -- 예: created_at, updated_at 등\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "> **※ 주의**  \n",
      "> - `<타임스탬프컬럼>` 부분을 실제 날짜/시간 컬럼(예: `created_at`, `log_time` 등)으로 바꾸어 주세요.  \n",
      "> - 순서 없이 단순히 어떤 10개라도 가져오길 원한다면 `ORDER BY` 절을 생략하고 `LIMIT 10;` 만 사용하면 됩니다.  \n",
      "\n",
      "```sql\n",
      "-- 순서 없이 단순히 10개 가져오기\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "필요에 따라 컬럼을 제한하거나 필터링 조건을 추가해 주세요.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3539e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
