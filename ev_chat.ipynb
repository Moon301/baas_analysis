{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f904e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "EV Performance\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"EV Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66c1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public ìŠ¤í‚¤ë§ˆ í…Œì´ë¸” ëª©ë¡: ['bw_segment_states', 'battery_performance_ranking', 'bw_segments', 'bw_data', 'bw_dashboard', 'car_type', 'bw_vehicle_status', 'battery_performance_scores_per_segment', 'mv_dashboard_stats', 'mv_dashboard_car_type_stats', 'mv_bw_monthly', 'ev_battery_capacity', 'bw_charging_type']\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    port=5432,\n",
    "    dbname='postgres',\n",
    "    user='postgres',\n",
    "    password='keti1234!'\n",
    ")\n",
    "\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "# cur.execute(\n",
    "#     \"\"\"\n",
    "#     SELECT table_name \n",
    "#     FROM information_schema.tables \n",
    "#     WHERE table_schema = 'public'\n",
    "#     ORDER BY table_name\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "cur.execute(\n",
    "    \"\"\"\n",
    "SELECT c.relname AS object_name,\n",
    "       d.description\n",
    "FROM pg_class c\n",
    "LEFT JOIN pg_description d ON d.objoid = c.oid\n",
    "WHERE c.relkind IN ('r','m','v')  -- r=table, m=matview, v=view\n",
    "  AND c.relnamespace = 'public'::regnamespace;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "tables = cur.fetchall()\n",
    "\n",
    "table_list = [t[0] for t in tables]\n",
    "print(\"Public ìŠ¤í‚¤ë§ˆ í…Œì´ë¸” ëª©ë¡:\", table_list)\n",
    "    \n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8504f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b08dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mgeneral_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**bw_data ìƒìœ„ 10ê°œ í–‰ ì¡°íšŒí•˜ê¸°**\n",
      "\n",
      "ì•„ë˜ ì˜ˆì‹œëŠ” **SQL**ê³¼ **Python (pandas)** ë‘ ê°€ì§€ ë°©ë²•ì„ í•¨ê»˜ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.  \n",
      "í•„ìš”í•œ í™˜ê²½ì— ë§ê²Œ í•œ ê°€ì§€ ë°©ë²•ì„ ì„ íƒí•´ì„œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1ï¸âƒ£ SQL ìœ¼ë¡œ ì¡°íšŒ (MySQL / PostgreSQL / SQLite ë“±)\n",
      "\n",
      "```sql\n",
      "-- ê°€ì¥ ìƒìœ„ 10ê°œì˜ í–‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "LIMIT 10;          -- MySQL / PostgreSQL / SQLite\n",
      "-- ë˜ëŠ”\n",
      "SELECT TOP 10 *\n",
      "FROM bw_data;      -- SQL Server\n",
      "```\n",
      "\n",
      "- `LIMIT 10` : ì²« ë²ˆì§¸ 10ê°œ í–‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.  \n",
      "- `TOP 10` : SQL Server ì „ìš© êµ¬ë¬¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "í•„ìš”í•˜ë‹¤ë©´ ì •ë ¬ ê¸°ì¤€ì„ ì§€ì •í•´ì„œ ê°€ì¥ ìµœê·¼ ê¸°ë¡ì´ ë‚˜ì˜¬ ìˆ˜ ìˆë„ë¡ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "ORDER BY created_at DESC\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 2ï¸âƒ£ Python (pandas) ìœ¼ë¡œ ì¡°íšŒ\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# ì˜ˆì‹œ: CSV íŒŒì¼ì´ ìˆëŠ” ê²½ìš°\n",
      "# df = pd.read_csv('bw_data.csv')\n",
      "\n",
      "# í˜¹ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°”ë¡œ ì½ì–´ì˜¬ ë•Œ\n",
      "# conn = ...  # DB ì—°ê²°\n",
      "# df = pd.read_sql('SELECT * FROM bw_data', conn)\n",
      "\n",
      "# ìƒìœ„ 10ê°œ í–‰ í™•ì¸\n",
      "top10 = df.head(10)\n",
      "print(top10)\n",
      "```\n",
      "\n",
      "- `df.head(10)` : DataFrameì˜ ì²« 10ê°œ í–‰ì„ ë°˜í™˜í•©ë‹ˆë‹¤.  \n",
      "- ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì ‘ ì½ì–´ì˜¬ ë•ŒëŠ” `pd.read_sql()`ì„ ì‚¬ìš©í•˜ë©´ í¸ë¦¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 3ï¸âƒ£ Jupyter Notebook ë“±ì—ì„œ ë°”ë¡œ ì‹œê°í™”\n",
      "\n",
      "```python\n",
      "top10.style.set_caption('bw_data ìƒìœ„ 10ê°œ í–‰')\n",
      "```\n",
      "\n",
      "ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ í‘œê°€ ê¹”ë”í•˜ê²Œ í‘œì‹œë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ì°¸ê³ ì‚¬í•­\n",
      "\n",
      "- **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°**: `pandas.read_sql()` ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” `sqlalchemy` ë˜ëŠ” `psycopg2`, `pymysql` ë“± ì—°ê²° ë“œë¼ì´ë²„ê°€ í•„ìš”í•©ë‹ˆë‹¤.  \n",
      "- **ë°ì´í„°ê°€ í´ ë•Œ**: `LIMIT 10` ëŒ€ì‹  `FETCH FIRST 10 ROWS ONLY` ê°™ì€ ANSI SQL êµ¬ë¬¸ì„ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.  \n",
      "- **ì •ë ¬ ì—†ì´ ì¡°íšŒ**: í…Œì´ë¸”ì´ ì¸ë±ìŠ¤ë‚˜ íŒŒí‹°ì…˜ì— ë”°ë¼ ìˆœì„œê°€ ë³´ì¥ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ê¼­ í•„ìš”í•œ ê²½ìš°ëŠ” `ORDER BY` ë¥¼ ëª…ì‹œí•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "í•„ìš”í•˜ì‹  ë¶€ë¶„ì´ ë” ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸš€\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import invoke_graph, stream_graph, random_uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "select_model = \"gpt-oss:20b\" #  FRONTEND ì—ì„œ ë„˜ì–´ì˜¨ ëª¨ë¸ ì •ë³´\n",
    "\n",
    "class EvState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    db_info: Annotated[list, \"DB Info\"]  # DB ì •ë³´\n",
    "    user_question: Annotated[str, \"Question\"]  # ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    db_query:  Annotated[str, \"DB Query\"]  # DB ì¿¼ë¦¬ ìƒì„±\n",
    "    db_result: Annotated[str, \"DB Answer\"]  # DB ì¿¼ë¦¬ ë‹µë³€\n",
    "    \n",
    "    \n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "\n",
    "    # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒì„ ìœ„í•œ ë¦¬í„°ëŸ´ íƒ€ì… í•„ë“œ\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question, ì „ê¸°ì°¨, ë°°í„°ë¦¬ë“±ê³¼ ê°™ì€ ì§ˆë¬¸ì´ë©´ 'yes'ë¥¼ ë°˜í™˜í•˜ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 'no'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# router\n",
    "def router_question_node(state: EvState) -> EvState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    system = \"\"\"You are an expert at routing a user question. ì „ê¸°ì°¨, ë°°í„°ë¦¬ë“±ê³¼ ê°™ì€ ì§ˆë¬¸ì´ë©´ 'yes'ë¥¼ ë°˜í™˜í•˜ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 'no'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.\"\"\"\n",
    "\n",
    "    # Routing ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "    route_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ êµ¬ì¡°í™”ëœ LLM ë¼ìš°í„°ë¥¼ ê²°í•©í•˜ì—¬ ì§ˆë¬¸ ë¼ìš°í„° ìƒì„±\n",
    "    question_router = route_prompt | structured_llm_router\n",
    "    response = question_router.invoke(state[\"user_question\"])\n",
    "    \n",
    "    if response.binary_score == \"yes\":\n",
    "        return \"db_search\"\n",
    "    else:\n",
    "        return \"general_answer\"\n",
    "# ë…¸ë“œ\n",
    "\n",
    "# ì¼ë°˜ ë‹µë³€ ë…¸ë“œ\n",
    "def general_answer(state: EvState) -> EvState:\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ìƒë‹´ì‚¬ KETI ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\"),\n",
    "            (\"user\", \"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | ChatOllama(model=select_model)\n",
    "    \n",
    "    response = chain.invoke({\"question\": state[\"user_question\"]})\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# DB í…Œì´ë¸” ì¡°íšŒ ë…¸ë“œ\n",
    "\n",
    "def db_search(state: EvState) -> EvState:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT c.relname AS object_name,\n",
    "        d.description\n",
    "    FROM pg_class c\n",
    "    LEFT JOIN pg_description d ON d.objoid = c.oid\n",
    "    WHERE c.relkind IN ('r','m','v')  -- r=table, m=matview, v=view\n",
    "    AND c.relnamespace = 'public'::regnamespace;\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    tables = cur.fetchall()\n",
    "\n",
    "    table_list = [t[0] for t in tables]\n",
    "    print(\"Public ìŠ¤í‚¤ë§ˆ í…Œì´ë¸” ëª©ë¡:\", table_list)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return {\"db_info\": table_list}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DB ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ\n",
    "def generate_query(state: EvState) -> EvState:\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a helpful assistant that generates í¬ìŠ¤íŠ¸ê·¸ë˜ SQL queries. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ë§ê³  ì¿¼ë¦¬ë¬¸ë§Œ ìƒì„±í•´\"),\n",
    "            (\"user\", \"Generate a SQL query to answer the following question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | ChatOllama(model=select_model)\n",
    "    response = chain.invoke({\"question\": state[\"user_question\"]})\n",
    "    return {\"db_query\": response.content}\n",
    "\n",
    "\n",
    "# DB ì¡°íšŒ ë…¸ë“œ\n",
    "def db_query(state: EvState) -> EvState:\n",
    "    conn = psycopg2.connect(\n",
    "        host='localhost',\n",
    "        port=5432,\n",
    "        dbname='postgres',\n",
    "        user='postgres',\n",
    "        password='keti1234!'\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    query = state[\"db_query\"].replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchall()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return {\"db_result\": result}\n",
    "\n",
    "# ë¶„ì„ ë‹µë³€ ë…¸ë“œ\n",
    "def analyze_answer(state: EvState) -> EvState:\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"DBì—ì„œ ì¡°íšŒëœ ë‹¤ìŒ ë‚´ìš©ì„ ë³´ê³  ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ë¶„ì„í•œ ë‚´ìš©ì„ ë‹µë³€í•˜ì„¸ìš”.  db_result:\\n{db_result}\"),\n",
    "            (\"user\", \"Generate a SQL query to answer the following question: {question}\"),\n",
    "        ]\n",
    "        )\n",
    "    chain = prompt | ChatOllama(model=select_model)\n",
    "    response = chain.invoke({\"question\": state[\"user_question\"],\"db_result\": state[\"db_result\"] })\n",
    "\n",
    "    \n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# langgraph.graphì—ì„œ StateGraphì™€ ENDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "workflow = StateGraph(EvState)\n",
    "\n",
    "# ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "workflow.add_node(\"router_question_node\", router_question_node)\n",
    "workflow.add_node(\"general_answer\", general_answer)\n",
    "workflow.add_node(\"db_gen_query\", db_query)\n",
    "workflow.add_node(\"generate_query\", generate_query)\n",
    "workflow.add_node(\"analyze_answer\", analyze_answer)\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    router_question_node,\n",
    "    {\n",
    "        \"db_search\": \"generate_query\",\n",
    "        \"general_answer\": \"general_answer\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"generate_query\", \"db_gen_query\")\n",
    "workflow.add_edge(\"db_gen_query\", \"analyze_answer\")\n",
    "workflow.add_edge(\"analyze_answer\", END)\n",
    "workflow.add_edge(\"general_answer\", END)\n",
    "\n",
    "\n",
    "# ê¸°ë¡ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•©ë‹ˆë‹¤.\n",
    "app= workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = EvState(user_question=\"bw_data ìƒìœ„ ì—´ê°œ ì¡°íšŒ\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e9f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mgeneral_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì €ë„ ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”! ì–¸ì œë“  ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”. ğŸ˜Š\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "response = invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e0e3326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤ ğŸ˜Š  \\nì €ëŠ” KETI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•˜ì‹  ì •ë³´ê°€ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = app.invoke(inputs, config)\n",
    "\n",
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f4f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mgeneral_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš” ğŸ˜Š  \n",
      "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = EvState(user_question=\"ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4098e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mgenerate_query\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mdb_query\u001b[0m:\n",
      "SELECT * FROM bw_data LIMIT 10;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mdb_gen_query\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 23, 465000), 54784.0, 79.5, 100.0, 363.4, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.025111111111107, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 26, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.024888888888885, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 29, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.025999999999995, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 32, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.026222222222217, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 35, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.0, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.026666666666663, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 38, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.026888888888885, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 41, 466000), 54784.0, 79.5, 100.0, 363.5, 17.7, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027111111111108, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 45, 465000), 54784.0, 79.5, 100.0, 363.5, 17.7, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027111111111107, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 48, 465000), 54784.0, 79.5, 100.0, 363.5, 17.6, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027555555555552, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "('V012BE0021', datetime.datetime(2025, 2, 9, 4, 57, 51, 465000), 54784.0, 79.5, 100.0, 363.5, 17.7, 46682.1, 0.0, Decimal('1'), Decimal('0'), 4.04, 4.02, 4.027333333333329, 4.02, 7.0, 5.0, 6.2, 6.0, None, None, None, None, None, None, None, None, None)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36manalyze_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mmessages\u001b[0m:\n",
      "ì•„ë˜ì™€ ê°™ì´ **`bw_data`** í…Œì´ë¸”ì˜ ìƒìœ„ 10ê°œì˜ ë ˆì½”ë“œë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "```sql\n",
      "-- ê°€ì¥ ìµœê·¼ 10ê°œì˜ ë ˆì½”ë“œë¥¼ ê°€ì ¸ì˜¤ë ¤ë©´\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "ORDER BY <íƒ€ì„ìŠ¤íƒ¬í”„ì»¬ëŸ¼> DESC   -- ì˜ˆ: created_at, updated_at ë“±\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "> **â€» ì£¼ì˜**  \n",
      "> - `<íƒ€ì„ìŠ¤íƒ¬í”„ì»¬ëŸ¼>` ë¶€ë¶„ì„ ì‹¤ì œ ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼(ì˜ˆ: `created_at`, `log_time` ë“±)ìœ¼ë¡œ ë°”ê¾¸ì–´ ì£¼ì„¸ìš”.  \n",
      "> - ìˆœì„œ ì—†ì´ ë‹¨ìˆœíˆ ì–´ë–¤ 10ê°œë¼ë„ ê°€ì ¸ì˜¤ê¸¸ ì›í•œë‹¤ë©´ `ORDER BY` ì ˆì„ ìƒëµí•˜ê³  `LIMIT 10;` ë§Œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.  \n",
      "\n",
      "```sql\n",
      "-- ìˆœì„œ ì—†ì´ ë‹¨ìˆœíˆ 10ê°œ ê°€ì ¸ì˜¤ê¸°\n",
      "SELECT *\n",
      "FROM bw_data\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "í•„ìš”ì— ë”°ë¼ ì»¬ëŸ¼ì„ ì œí•œí•˜ê±°ë‚˜ í•„í„°ë§ ì¡°ê±´ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3539e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
